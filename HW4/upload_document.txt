Complete this document and upload along with your prediction results and your code.

### Method Name ###
Use a phrasal name to describe your method, e.g. training a BiLSTM cross-encoder from scratch, fine-tuning RoBERTa-large-MNLI, etc.
- Fine-tuning ALBERT (albert-base-v2)



### Sentence pair encoder ###
Use up to 5 sentences to describe your encoder for the sentence pairs. Need to mention the following:
Is it a bi-encoder or cross-encoder?
What type of encoder (LSTM, Transformer, etc.)
Is it based on a pre-trained model (BERT-large? RoBERTa-large-SNLI? BART-large-MNLI?) or completely trained from scratch by yourself (then how do you characterize the words and aggregate them into sentence representations)?

- The type of encoder used in the assignment is a transformer.
- The encoder used for sentence pairs is a cross-encoder.
- It is based on a pre-trained 'albert-base-v2' model.
- All sentence pairs are stored in a dataframe first. Then the sentences are tokenized (using AutoTokenizer from the pre-trained BERT model). Then every precondition (sentence1) and statement (sentence2) is selected at the specified index in the dataframe, and special tokens are added to prepare an encoded pair input. 
- The inputs to the model are aggregated as a pair of sentences for classification by concatenating and adding special tokens required by the ALBERT model (eg: pair of sequences: [CLS] A [SEP] B [SEP]).



### Training & Development ###
Up to 5 sentences: how did you evaluate your solution using the dev set before submitting to the leaderboard? What are some key hyperparameter values (e.g., optimizer, learning rate, batch size, etc.)? Did you fine-tune your model or just conducted zero-shot transfer from a pre-trained model? If fine-tuning, what portion of data did you use and how did you terminate the training (using a fixed #epochs, early stopping based on dev set performance)?

- The solution is evaluated as follows: The model is trained using the sentence pairs and labels present in the training dataset alone. 
- Once the model is trained completely, the evaluation of the entire dev set is performed considering only sentence pairs (precondition and statement), and the classification labels(0/1) of the dev set are predicted/identified. The dev dataset accuracy is then computed by comparing the predicted classification labels with the available(provided) labels in the dev dataset.
- Key hyperparameter values:
  Optimiser: AdamW
  Learning rate: 2e-5
  Batch size: 16
  Epochs: 4
- Fine-tuning is done on the training dataset provided, based on the model's performance on the validation/dev dataset.
- The training was terminated using a fixed number of epochs based on the dev set accuracy.


  
### Other methods ###
Did you try other methods than the submitted one?
- Yes. Other methods checked include BiLSTM using PyTorch from scratch (~66% dev set accuracy), BERT and ALBERT transformers from scratch (~52% and ~77% dev set accuracies respectively), Fine tuning transformer (BERT model) for sentence pair classifications (~75% dev set accuracy). 
- Fine-tuning ALBERT (albert-base-v2) gave me the highest (~85% dev dataset accuracy) from all the methods tried.



### Packages ###
List the key python packages you have used in this assignment.
- PyTorch, NumPy, Pandas, transformers, tqdm
